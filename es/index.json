[{"content":"Algunos proyectos laborales # ¿Sobre qué tuitean los senadores mexicanos? ( R, Shiny)\nSimulador de ahorro para el retiro para jóvenes (R, SQLite, Shiny)\nPanorama de los profesionistas en México (Python, R, Shiny)\nEl papel de México en la migración centroamericana (Javascript)\nMapa de denuncia ciudadana (R, Leaflet)\n","date":"24 septiembre 2022","permalink":"/es/projects/","section":"","summary":"Algunos proyectos laborales # ¿Sobre qué tuitean los senadores mexicanos? ( R, Shiny)","title":""},{"content":"","date":"24 septiembre 2022","permalink":"/es/tags/catboost/","section":"Tags","summary":"","title":"catboost"},{"content":"","date":"24 septiembre 2022","permalink":"/es/tags/gradient-boosting/","section":"Tags","summary":"","title":"Gradient boosting"},{"content":"","date":"24 septiembre 2022","permalink":"/es/tags/machine-learning/","section":"Tags","summary":"","title":"Machine learning"},{"content":" Data Analyst | Data Scientist | Python | R | Machine Learning Me encanta la tecnología e iniciar proyectos de visualización de datos. Autodidacta en programación y formación en progreso en machine learning. Mis proyectos personales están disponibles en esta página.\n","date":"24 septiembre 2022","permalink":"/es/","section":"Orlando F. Vázquez","summary":"Data Analyst | Data Scientist | Python | R | Machine Learning Me encanta la tecnología e iniciar proyectos de visualización de datos.","title":"Orlando F. Vázquez"},{"content":" ¿Qué tan altas fueron las probabilidades de morir por COVID-19 en México durante 2020? En los días más graves de la pandemia superiores al 90% Impacto de la COVID-19 # La pandemia de COVID-19 ha tenido consecuencias graves en todo el mundo y en México no ha sido la excepción. En determinados meses, la cantidad de muertes ocasionadas por esta enfermedad puso al límite al sistema de salud y aún persisten los efectos en muchos de los hospitales del país. El INEGI ha reportado que del total de muertes registradas durante el 2020 (1,086,743), 18.4% de estas (200,256) fueron debido a la COVID-19, siendo la primer causa de muerte en el caso de los hombres. Lo anterior se puede observar más detalladamente analizando la base de datos de defunciones durante el 2020 disponible en la página de la Secretaria de Salud del Gobierno Federal.\nPara tratar de dar contexto a la situación que se vivió en el país durante ese año generé un modelo, a partir de esta base de datos, que pudiese predecir, en función de la edad, género, lugar de fallecimiento, escolaridad, fecha de fallecimiento, entre otras variables, cuáles fueron las probabilidades de que la causa de defunción de las personas se hubiese registrado como COVID-19.\nEste modelo fue desarrollado con un algoritmo de gradient boosting, utilizando la librería de Catboost, logrando obtener un F1 Score de .80 después de realizar varios ajustes. Tomando en cuenta los cambios en la mortalidad por COVID-19 que se han presentado en años posteriores como consecuencia de los esfuerzos de vacunación llevados a cabo a nivel mundial, no es un modelo que pueda extrapolarse a años posteriores. En este sentido es más un ejercicio para poner en práctica conocimientos aprendidos en machine learning que un modelo predictivo e incluso, si se analiza detalladamente la base de datos puesta a disposición por la Secretaria de Salud se pueden encontrar y analizar resultados más detallados.\nProbabilidad de fallecimiento por COVID-19 # En lo que nos puede ayudar este modelo es tener una mejor idea de cuál fue la probabilidad de que una persona, en el transcurso de 2020, tuviese como causa de muerte la COVID-19, tomando en consideración las características sociodemográficas previamente mencionadas: género, edad, fecha de fallecimiento, localidad de fallecimiento, ser derechohabiente, entre otras. Lo que encontramos es que la probabilidad de que sea esta la causa de muerte aumenta significativamente, en concordancia con el gráfico superior que muestra que la primera ola de COVID-19 en 2020.\nPor ejemplo, la posibilidad de que un hombre de 68 años, en la Ciudad de México, en el municipio de Gustavo A. Madero, con Primaria incompleta, no derechohabiente, el 22 de diciembre de 2020, haya fallecido como consecuencia de la COVID-19 es de hasta el 92%, lo cual coincide con el pico más altos de fallecimientos en 2020 que se muestra el gráfico de arriba.\nEl resultado cambia radicalmente si consideramos el caso de una mujer de esa misma edad y en esa misma localidad, pero fallecida en la primera quincena de abril. En este caso la probabilidad de que la causa de fallecimiento haya sido COVID-19 disminuye a 39%. Jugando un poco más con las condiciones de deceso, se podrán encontrar patrones muy interesantes en distintas regiones del país en función de la temporalidad seleccionada y las condiciones demográficas.\n","date":"24 septiembre 2022","permalink":"/es/projects/prediccion-covid19/","section":"","summary":"¿Qué tan altas fueron las probabilidades de morir por COVID-19 en México durante 2020? En los días más graves de la pandemia superiores al 90%","title":"Prediciendo la probabilidad de muerte por COVID-19 en México durante 2020"},{"content":"","date":"24 septiembre 2022","permalink":"/es/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":"28 agosto 2022","permalink":"/es/tags/bloom/","section":"Tags","summary":"","title":"BLOOM"},{"content":"","date":"28 agosto 2022","permalink":"/es/tags/lstm/","section":"Tags","summary":"","title":"LSTM"},{"content":" Sobre la trayectoria seguida para lograr generar texto en español Generación de texto en español # Quiero empezar este texto mostrando inmediatamente el resultado del primer proyecto que realicé en machine learning: un generador de texto en español a partir de hacer fine-tuning a un modelo existente (BLOOM) usando Transformers. El entrenamiento se realizó a partir de las transcripciones de las conferencias de prensa y discursos públicos del presidente de México, Andrés Manuel López Obrador, por lo que el texto generado se caracteriza por replicar su particular manera de comunicarse de forma verbal.\nA partir de aquí el relato de la trayectoria para llegar a este resultado, aclarando que el texto no pretende ser un tutorial ni explicar los detalles específicos para la creación de esta app.\nPlanteando el proyecto # En mi trayectoria por aprender recurrent neural networks (RNN) decidí que uno de los primeros proyectos que trabajaría de forma personal fuese uno de generación de texto a nivel de caracteres, lo cual me ayudaría a comprender mejor su funcionamiento y a poner en práctica lo aprendido. Decidí iniciar el proyecto trabajando a partir textos de Donald Trump, al considerar que habría mucho material disponible, si bien pronto se volvió evidente que no era precisamente la idea más novedosa.\nPara darle un poco más de originalidad y diversidad al asunto, elegí trabajar no a partir de textos escritos por el expresidente en libros o tweets, sino a partir de las transcripciones de sus discursos públicos, por lo que podríamos ver este ejercicio como un generador de discursos.\nPrimeros resultados y cambio de enfoque # Utilizando una red neuronal LSTM (Long Short Term Memory) en PyTorch y con un entrenamiento de 30 epochs los primeros resultados obtenidos fueron\u0026hellip; curiosos:\nThe media is going to be talking about the farmers. They’re a very good job and we are trying to be a great job that they have to be and with the problem. I think it’s not allowed to get it, they don’t want to say it. They want to give them all the time. I think it will start to get along with a land. We had a great service and the first time to say the sand and energy independence, but when the suburbs, they’ve been able to do that\u0026hellip;\nComo ejercicio resultó francamente entretenido y el resultado divertido de leer. El texto generado, si bien se puede apreciar el estilo de expresarse del expresidente estadounidense, carece de coherencia. Sin embargo en un modelo entrenado desde cero, con un hardware limitado, era esperable que los resultados no fueran espectaculares en el primer intento. Habiendo leído ya un poco de literatura de sobre transfer learning me pareció que este podría ser un excelente ejercicio para ponerlo en la práctica y ver los beneficios que podría obtener utilizando modelos previamente entrenados.\nUtilizando transformers y GPT-2 # El siguiente paso en este proyecto fue documentarme sobre el funcionamiento de la librería Transformers de Hugging Face y tratar de mejorar los resultados previamente obtenidos. El modelo utilizado en esta ocasión fue GPT-2, modelo de generación de texto puesto a disposición por OpenAI en 2019. Después de mucha prueba y error y tras ir ajustando diversos parámetros en el modelo, logre generar los siguientes textos:\nSe observan resultados de mucha mayor calidad que en el primer ejercicio y en una cantidad de tiempo relativamente breve, lo cual indicaba que este era un buen camino por seguir.\nModelos para generar texto en español # Sin embargo, lo que realmente deseaba realizar desde un primer momento era la generación de texto en español, tratando de replicar la calidad de los resultados obtenidos entrenando el modelo en inglés. De ahí que consideré que una vez obtenidos resultados aceptables en la generación de texto en inglés, sería sencillo replicar los resultados con texto en español. Desafortunadamente, esto no fue así y ya ciertos artículos mencionan las limitaciones del modelo GPT-2 para la generación de texto en idiomas distintos al inglés.\nSi bien se encuentran disponibles en Hugging Face modelos de GPT-2 entrenados con un corpus en español, tras haber leido recientemente sobre esta iniciativa, decidí que sería un buen ejercicio probar el modelo multilenguaje de BLOOM, proyecto de ciencia abierta y de acceso libre entrenado para generar texto en 46 idiomas y que fue hecho público en julio de este mismo año.\nWeb scraping # En esta ocasión decidí que la generación de texto en español sería a partir de transcripciones conferencias y discursos del presidente Andrés Manuel López Obrador, y el motivo por el cual seleccionar a este personaje fue similar al anterior: amplia disponibilidad de material en internet. El proceso para obtener las transcripciones partió de hacer web scraping desde la página del presidente donde se encuentran disponibles estas transcripciones.\nUtilizando Scrapy obtuve 1609 transcripciones de conferencias de prensa y discursos en eventos públicos del 4 de diciembre de 2018 al 21 de julio de 2022. Una vez realizada la limpieza de las transcripciones y manteniendo únicamente las participaciones del presidente López Obrador y eliminando las participaciones de cualquier otro personaje, esto se tradujo en 38 MB de discursos y conferencias transcritas, equivalente a 36,795,294 caracteres.\nEntrenamiento del modelo y conclusiones # Para poder entrenar el modelo y debido a las limitaciones de hardware tuve que hacer varios ajustes: en primer lugar utilizar el modelo de BLOOM más pequeño disponible (que aun así cuenta con 560 millones de parámetros), mantener únicamente el 25% del texto obtenido, que a su vez, para evitar problemas con la RAM, tuve que dividir en oraciones completas con un máximo de 1000 caracteres.\nOtra limitación adicional, fue que al momento de programar la aplicación utilizando Gradio y al subirla a Hugging Spaces, por cuestión del tiempo requerido para generar el texto, vi necesario limitar la generación a solo 100 palabras.\nEl resultado del fine tuning tras un entrenamiento de 5 epochs, es la generación de un texto decente, como se puede ver al inicio, que a diferencia de los primeros ejercicios, mantiene al menos una coherencia y estructura dentro de las oraciones generadas. Considero que aún hay margen de mejora y afortunadamente la API de transformers tiene la suficiente flexibilidad para ir ajustando distintos parámetros tanto en el entrenamiento como en la generación de texto. Espero subir próximamente un tutorial detallado sobre los pasos seguidos en este proyecto.\n","date":"28 agosto 2022","permalink":"/es/projects/generacion-de-texto/","section":"","summary":"Sobre la trayectoria seguida para lograr generar texto en español.","title":"Proyecto de generación de texto en español"},{"content":"","date":"28 agosto 2022","permalink":"/es/tags/rnn/","section":"Tags","summary":"","title":"RNN"},{"content":"","date":"28 agosto 2022","permalink":"/es/tags/transformers/","section":"Tags","summary":"","title":"Transformers"},{"content":"","date":"1 enero 0001","permalink":"/es/categories/","section":"Categories","summary":"","title":"Categories"}]